%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Security model}
\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi

\section{Introduction}
\label{sec:syntaxModel}
In this chapter, we first describe the protocol and its security model generically.
We then go into details and further use it as a framework for our specific
proposals in later chapters. In order to precisely grasp  the definition of security,
we will describe the protocols' security models in terms of \textbf{attack
  games} played bettwen two parties: a \textbf{challenger} and an
\textbf{adversary}. Generally, the challenger \(\challenger\) follows a simple,
fixed protocol and the adversary \(\attacker\) may follow an arbitrary and
efficient protocol. The two players send messages back and forth to each other
as specified in their protocols, and, at the end of the games, \(\attacker\)
outputs some value. The attack games define a probability space based on this
output value, and it defines the adversary's \textit{advantage}, which normally
measures the difference between the probabilities of two events in the given
probability space: One is the event that the adversary wins the \textit{real}
game; the other one is the event that the adversary wins the game with one (or
some) of the system's components replaced by an idealized version of such
component(s). The security proofs of protocols will also be organized as
sequences of games. This technique appears in the literature in different flavours
with different degrees of formalisation. For us, it provides a helpful tool
to reduce the complexity of security proofs that might otherwise become
messy and complicated. We note that the technique is only a tool to organize the
models and the proofs, the actual ideas for cryptographic constructions and
security analysis come from elsewhere, specifically the problems discussed in
the previous chapter.

\subsection{Desirable properties}
\label{sec:privacyProps}
According to \cite{jain201650}, a secure template solution to biometric
authentication should satisfy the following properties:
\begin{description}
\item[Non-invertibility:] It is computationally hard to rebuild an original
  template from an encrypted one.
\item[Non-linkability (Revocability):] It should be possible to revoke and to
  re-issue new encrypted templates using a new key when the database is
  compromised.
\item[Discriminability:] The secure scheme should not degrade the accuracy of
  the biometric authentication system.
\end{description}
\subsection{The threats}
\label{sec:privacyReqs}
There are common security threats to many authentication systems such as Trojan
horse, replay, man-in-the-middle (MITM) attack, etc. Biometrics authentication
systems are also vulnerable to such attacks. We can borrow ideas from secure
password-based schemes to address such issues. However, there are two categories
of vulnerabilities that are specific to biometric systems.  The first one is
impersonation, or spoofing, the attack happens at the client's side as the
adversary tries to cheat the system with counterfeit or invalid inputs.  The
other issue is at the server's side and yields privacy concerns.

We will discuss the formal models that capture all the known threats of
biometric authentication:
\begin{itemize}
\item Confidential data leakage due to attacks on the template database: Server
  breaches of biometric data always have catastrophic consequences
  (\cite{OPMsays563:online}), as we cannot change our fingerprints as easily as
  changing our passwords.
\item Hill-Climbing attack from the server's side: This is a privacy threat
  where the server tries to compute good inputs $X$ from the distance
  information between $X$ and $Y$ (\cite{uludag2004attacks},
  \cite{higo2015privacy}). Note that Hill-Climbing attack by the client is very
  limited due to the limitation of the number of false authentication attempts
  in almost every biometric authentication system.
\item Impersonation by a malicious client when the secret key of the user is
  known (replay attack): This happens when an attacker has access to the user's
  device but not to his biometric data, as, for example, in stolen device
  scenarios (\cite{zhang2015fingerprints}).
\item Impersonation by a malicious client when the biometric template of the
  user is known (spoofing attack): This happens when an attacker collects
  biometric data and tries to reconstruct the template for authentication, as,
  for example, by rebuilding fingerprints from captured photos
  (\cite{zhang2015fingerprints},\cite{feng2011fingerprint}).
\item Cross matching of biometric data among databases: This threat uses
  information of the same user from different compromised databases to
  reconstruct the biometric template.
\end{itemize}

\section{The generic model}

\begin{description}
\item[Entities:] There can be 2 or 3 typical entities involved in a secure
  biometric authentication system. The user $\mathcal{U}$, an authentication
  server $\mathcal{S}$, and a decryptor, who is a third party trusted by both
  the user and the server. The decryptor appears in some systems
  (\cite{mandal2015comprehensive}, \cite{hirano2013cryptographically},
  \cite{higo2015privacy}), with the assumption that there is no collusion
  between this entity and $\user$ or $\server$. In our work, we avoid the
  assumption of a trusted decryptor party, so that only two parties are left:
  $\user$ and $\server$.
\item[Biometrics Features in non-private setting] In biometric authentication
  systems (e.g., fingerprint authentication system), a user $\mathcal{U}$ first
  registers his fingerprint template $X$ on the server
  $\mathcal{S}$. $\mathcal{U}$ later authenticates before $\mathcal{S}$ using
  the same finger with a template $Y$, $\server$ uses an algorithm $Verify(X,Y)$
  to obtain the result of the authentication: \textbf{Accept} or
  \textbf{Reject}. Different fingerprint systems might use different features of
  fingers such as minutia or fingercode to compute the distance $\Delta$ between
  $X$ and $Y$ within the algorithm $Verify$. The distance $\Delta$ is compared
  to some predifined threshold value $\tau$ to determine the result of the
  authentication. We refer the reader to \cite{jain2007handbook} for biometric
  feature extraction and
  comparison techniques.

  Unlike password based systems, where $\user$ always uses one and the same
  query for many authentication trials, all biometric systems have the concept
  of False Acceptance Rate (FAR) (for the system \textbf{Accept}ing an incorrect
  template), and False Rejection Rate (FRR), (for the system \textbf{Reject}ing
  a genuine one).  As balancing these 2 rates while keeping good performances is
  one of the main challenges that fingerprint verification algorithms
  \cite{FVConGoi2:online} need to face, we also reflect these two rates in our
  models.

\item[Algorithms and Procedures in privacy-preserving settings:] We describe the
  high-level constructions of the privacy-preserving protocol as follows:
  \begin{description}
  \item[Enrol.] This procedure inserts records into the server's database.
    \begin{itemize}
    \item Input: Client: identity $k$, a registered template $X_k$; Server:
      Parameters of the cryptographic tools used.
    \item Output: A public-private key pair $(sk_k, pk_k)$ for the user
      $\user_k$. The server stores the protected template of $T_k$ (which can be
      some encryption of $X_k$).
    \end{itemize}
  \item[Auth.] This procedure allows a user to authenticate to the system.
    \begin{itemize}
    \item Input: Client: identity $k$, a query template $Y_k$ and the secret key
      $sk_k$; Server: record $(k, T_k, pk_k)$
    \item Output: The server computes the authentication result
      $res=\{\textbf{Accept,Reject}\}$. The transcript of the protocol can also
      be obtained: We denote \(V_{c}\) and \(V_{s}\) to be the \textit{view} of
      the client and the server received from the protocol execution.
    \end{itemize}

  \item[Correctness Requirement:] A genuine user $\user_k$ executes
    $(sk_k, T_k) \gets \mathbf{Enroll}(k, X_k)$ using a $X_k \in Supp(D_k)$ and
    later uses his biometric template $Y_k \randomsample D_k$ to perform
    $$res \gets \mathbf{Auth}( (k, Y_k, sk_k), (k, T_k, pk_k))$$
    The privacy-preserving protocol works correctly if the FRR under this system
    is exactly equal to the FRR of the non-privacy preserving system:
    \[
      Pr[res = verify(X_k,Y_k)] = 1
    \]
  \end{description}
\end{description}

\subsection{The privacy preserving model}
\begin{description}
\item[Privacy against an Honest But Curious server:] The security model is defined in terms of the following security games.
  % Although the model assumes the server behaves honestly \emph{within} the protocol (since we our main aim is security
  % against passive exposure of server contents), it does allow the server to adversarially choose the client's
  % \emph{input} query templates $Y_i$ to try to learn about the attacked user's template $X_k$, so our model implies
  % security against `hill climbing attacks'~\cite{adler2005vulnerabilities}.

\item[The real game $\mathbf{Real}_{\attacker}(D_k,X_k)$:] This is the game for a privacy attack against the
  privacy-preserving protocol for the underlying biometric system, between an attacker $\attacker$ and a challenger
  $\challenger$. The input of the game is an attacked $\user_k$ biometric distribution $D_k \in D_{bio}$ and a user
  template $X_k \in Supp(D_k)$.
  \begin{enumerate} %$\challenger$ selects a $\user_k$ with $D_k \in D_{bio}$ . For any $X_k \in Supp(D_k)$,
  \item $\challenger$ runs $(T_k, sk_k) \gets \mathbf{Enrol}(k,X_k)$ and sends $T_k$ to $\attacker$.
  \item For $i = 1 \dots q$:
    \begin{itemize}
    % \item $\attacker$ chooses and sends $Y_i$ to $\challenger$
    \item $\challenger$ samples \(Y_{i} \randomsample D_{k}\)
    \item $\challenger$ simulates the \textbf{Auth} protocol, playing the roles of both the client and the server:
      \[
        res \gets \mathbf{Auth_i}((k, Y_i, sk_k), (k, T_k, pk_k))
      \]
    \item $\challenger$ sends the view $V_s^{i}$ to $\attacker$.
    \end{itemize}
  \item $\attacker$ outputs a bit $\beta$, representing some information that $\attacker$ has discovered about
    $(D_k,X_k)$. The game output is $\mathbf{Real}_{\attacker}(D_k,X_k) = \beta$.
  \end{enumerate}

\item[The ideal game $\mathbf{Ideal}_{\attacker'}(D_k,X_k)$:] This is the game for a privacy attack against an ideal
  privacy scenario for the underlying biometric authentication system, where an attacker $\attacker'$ interacts with a
  challenger $\challenger'$. The input of the game is an attacked $\user_k$ biometric distribution $D_k \in D_{bio}$ and a
  user template $X_k \in Supp(D_k)$. In this ideal game, the information $\attacker'$ can obtain about $(D_k,X_k)$ is the
  value of \(HD_{X_{k}, Y_{k}}\) and the bit $Verify(X_k,Y_i)$.
  \begin{enumerate}
  \item For $i = 1 \dots q$:
    \begin{itemize}
    \item $\attacker'$ chooses query template $Y_i \in \{0,1\}^n$ and sends it to $\challenger'$.
    % \item $\challenger'$ computes $res_i = verify(X_k, Y_i) \in \{\mathbf{Accept},\mathbf{Reject}\}$.
    \item $\challenger'$ sends $HD_{X,Y_{i}}$ to $\attacker'$.
    \end{itemize}
  \item $\attacker'$ output a bit $\beta'$, representing some information that
    $\attacker'$ has gathered about $(D_k,X_k)$. The game output is
    $\mathbf{Ideal}_{\attacker'}(D_k,X_k) = \beta'$.
  \end{enumerate}
\end{description}

Let \(W_{r}\) be the event that \(\attacker\) outputs $\beta = 1$ in the real game and let
\(W_{i}\) be the event that \(\attacker'\) output $\beta' = 1$ in the ideal game. We define
$\adv$'s \textbf{passive server security advantage} with respect to protocol $\pdv$ as
\[
\advantage{PS}{\adv,\pdv} = | Pr[W_{r}] - Pr[W_{i}]|
\]

\begin{definition}
  [Privacy Security against Server] We say that a biometric authentication
  protocol is $q$-private in the sense of biometric template privacy against an
  honest but curious server $\server$ if for every efficient real-game attacker
  $\attacker$, there exists an efficient ideal-game attacker $\attacker'$ such
  that, for all $(D_k,X_k)$ the following stands:
  \[
    \advantage{PS}{\adv,\pdv} \leq negl(n).
  \]
\end{definition}

Figure \ref{fig:passiveServerGame} and \ref{fig:passiveServerGameIdeal} show
schematic diagrams of the Privacy Security against Server games.

\begin{figure}[!h]
  \centering
  \begin{center}
    \begin{bbrenv}{PSGame}
      \begin{bbrbox}[name=Adversary, minheight=2cm]
        
      \end{bbrbox}
      \bbroutput{$\beta = A(D_{k}, X_{k})$}
      \begin{bbrchallenger}{PSChallenger}
        \begin{bbrbox}[name=Challenger]
          \pseudocode{
            \\
            (\pk,\sk) \gets KeyGen\\
            X_k \randomsample D_k\\
            T_k \gets \mathbf{enroll}(k,X_k)\\
            \text{For } i = 1,\dots,q:\\
            Y_k \randomsample D_k\\
            res_i = \mathbf{auth}(k,T_k,Y_k)
         } 
        \end{bbrbox}
      \end{bbrchallenger}
      \bbrchallengerqryto{top=$T_{k}$}
      \bbrchallengerqryto{top=$res_{i}$}
      \bbrchallengerqryto{top=$V_{s}^{i}$}
      % \bbrchallengerqryto{top=$m_{2}$}
    \end{bbrenv}
  \end{center}
  \caption{Passive Server Attack Game (Real Game)}
  \label{fig:passiveServerGame}
\end{figure}

\begin{figure}[!h]
  \centering
  \begin{center}
    \begin{bbrenv}{PSGameIdeal}
      \begin{bbrbox}[name=Adversary, minheight=2cm]
        
      \end{bbrbox}
      \bbroutput{$\beta' = A'(D_{k}, X_{k})$}
      \begin{bbrchallenger}{PSChallengerIdeal}
        \begin{bbrbox}[name=Challenger]
          \pseudocode{
            \\
            (\pk,\sk) \gets KeyGen\\
            X_k \randomsample D_k\\
            T_k \gets \mathbf{enroll}(k,X_k)\\
            \text{For } i = 1,\dots,q:\\
            Y_k \randomsample D_k\\
            res_i = Verify(X_k, Y_k)
         } 
        \end{bbrbox}
      \end{bbrchallenger}
      % \bbrchallengerqryto{top=$T_{k}$}
      % \bbrchallengerqryto{top=$res_{i}$}
      \bbrchallengerqryto{top=$res_{i}$}
      % \bbrchallengerqryto{top=$m_{2}$}
    \end{bbrenv}
  \end{center}
  \caption{Passive Server Attack Game (Ideal Game)}
  \label{fig:passiveServerGameIdeal}
\end{figure}

At several points of this thesis, we will refer to the terms ``efficient'' and
``negligible'' (which will be defined formally in a section below). Intuitively,
\textit{negligible} means so small as to be ``zero for practical purposes''. For
example, consider an event happening with probability \(2^{-100}\): we would
not worry about such an event occuring more than we would worry about a similar
event occurring with probability 0. Additionaly, an \textit{efficient
  adversary} is granted to run in a reasonable amount of time. Sometimes we
also use two other related terms: A value \(N\) is called \textit{super-poly} if
\(1/N\) negligible; and a \textit{poly-bounded} value is supposed to be a reasonably sized
number (we can say that the running time of any \textit{efficient} adversary is
a \textit{poly-bounded} value). We will use the results of the following lemma in
the security proofs:
\begin{lemma}
  If \(\epsilon\) and \(\epsilon'\) are negligible values, and \(Q\) and \(Q'\)
  are poly-bounded values, then
  \begin{itemize}
  \item \(\epsilon + \epsilon'\) is a negligible value
  \item \(Q + Q'\) and \(Q \cdot Q'\) are poly-bounded values
  \item \(Q \cdot \epsilon\) is a negligible value
  \end{itemize}
\end{lemma}

\begin{description}
\item[Security against a malicious client:] In this work, we aim at security
  against an active client, where an attacker $\attacker$ is assumed not to
  follow the protocol transcript.
  \begin{description}
  \item[Biometric Impersonation Attack Game.] FAR is the usual biometric
    impersonation probability, it is inherent to biometrics itself without any
    cryptographic protocols. We first discuss this security game (which will be
    refered to as \textit{biometric impersonation}), we then elaborate the
    discussion to account for models with privacy-preserving requirements.
    \begin{description}
    \item[Setup:] $\challenger$ samples $X_k \randomsample D_{k}$ from a random
      $\user_k$ ($D_k \randomsample D_{bio}$).
    \item[Query:] $\attacker$ is given access to the authentication oracle
      $verify(X_k,Y)$, which returns the authentication result of $\user_k$ with
      a query template $Y$. $\attacker$ has $q$ attempts to make queries, in
      each attempt, $\attacker$ chooses a $Y_{q}$ by himself and executes
      $verify(X_k,Y_{q})$.
    \item[Guess:] $\attacker$ outputs $Y_{q'}$ such that
      $verify(X_k,Y_{q'}) = \textbf{Accept}$.
    \end{description}

    Figure \ref{fig:maliciousNonPrivate} show the biometric
    imperationation (non private) attack game. Let $W_{0}$ be the event that
    $\attacker$ output $Y_{q'}$ such that
    $verify(X_{k},Y_{k}) = \mathbf{Accept}$ and let $p_{0} = \prob{W_{0}} $.
    \begin{figure}[!h]
      \begin{center}
        \begin{bbrenv}{nonPrivacyServer}
          \begin{bbrbox}[name=Adversary, minheight=2cm]
            \pseudocode{
              \\
              \text{For } i = 1,\dots,q:\\
              Y_i \gets \{0,1\}^n
           } 
          \end{bbrbox}
          \bbroutput{$Y_{q}'$}
          \begin{bbrchallenger}{nonPrivacyChallenger}
            \begin{bbrbox}[name=Challenger]
              \pseudocode{
                \\
                D_k \randomsample D_{bio}\\
                X_k \randomsample D_k\\
                res_i = Verify(X_k, Y_k)\\
              } 
            \end{bbrbox}
          \end{bbrchallenger}
          \bbrchallengerqryfrom{top=$Y_{k}$}
          % \bbrchallengerqryto{top=$res_{i}$}
          \bbrchallengerqryto{top=$res_{i}$}
          % \bbrchallengerqryto{top=$m_{2}$}
        \end{bbrenv}
      \end{center}
      \caption{Malicious Client Attack Game in Non-private setting}
      \label{fig:maliciousNonPrivate}
    \end{figure}

    
    % The advantage of $\attacker$ in the game is defined as
    % \[
    %   \textbf{Adv}^{bio}_\attacker(\lambda) = Pr[verify(X_k,Y_{q'}) =
    %   \mathbf{Accept}]
    % \]
    % In this basic model, when $q=1$, the $p_{0} = FAR$.  In other words, we can
    % say the advantage of $\attacker$ is
    % $ \textbf{Adv}^{bio}_\attacker(\lambda) \leq q\times FAR$.

  \item[Impersonation Attack Game.] This game captures the basic impersonation attack from a client
    \begin{description}
    \item[Setup:] The setup phase includes 2 steps:
      \begin{itemize}
      \item $\challenger$ samples $X_k \randomsample D_{k}$ from a random
        $\user_k$ ($D_k \randomsample D_{bio}$).
      \item $\challenger$ runs $\textbf{Enroll}(k, X_k)$, which returns $(sk_k, T_k)$.
      \end{itemize}
    \item[Query:] In the query phase:
      \begin{itemize}
      \item $\attacker$ is given access to the authentication oracle
        $\mathbf{Auth}(Y)$ returning the authentication result of $\user_k$ with
        a query template $Y$.

      \item $\challenger$ and $\attacker$ run $\mathbf{Auth()}$ $q$ times, For
        the $i^{th}$ run, $\attacker$ plays the client's role, choosing and
        sending $Y_i$ to $\challenger$, $\challenger$ plays the server's role,
        replying with $res_i = \mathbf{Auth}(Y_i)$.
      \end{itemize}
    \item[Guess:] $\attacker$ wins the game if it outputs $Y$ such that $\mathbf{Auth}(Y) = \textbf{Accepted}$.
    \end{description}
    Figure \ref{fig:impersonationAttackGame} show the impersonation attack
    game. Let $W_{1}$ be the event that $\attacker$ output $Y_{q'}$ such that
    $verify(X_{k},Y_{k}) = \mathbf{Accept}$ and let $p_{1} = \prob{W_{1}} $. We
    define $\adv$'s \textbf{active impersonation advantage} with respect to the
    protocol $\pdv$ as
    \[
      \advantage{AI}{\adv,\pdv} = |p_{1} - p_{0}|
    \]
    \begin{definition}
      [Active Client Impersonation.] A privacy-preserving biometrics
      authentication protocol \pdv is c-secure against active client
      impersonation if for all efficient adversary \adv, the value
      $\advantage{AI}{\adv,\pdv}$ is not larger than $c \times FAR$ of the
      non-private protocol.
    \end{definition}
      
    \begin{figure}[!h]
      \begin{center}
        \begin{bbrenv}{impersonationSecurity}
          \begin{bbrbox}[name=Adversary, minheight=2cm]
            \pseudocode{
              \\
              \text{For } i = 1, \dots, q:\\
              Y_i \gets \{0,1\}^n
            }
          \end{bbrbox}
          \bbroutput{$Y_{q}'$}
          \begin{bbrchallenger}{impersonationChallenger}
            \begin{bbrbox}[name=Challenger]
              \pseudocode{
                \\
                (\pk,\sk) \gets KeyGen\\
                D_k \randomsample D_{bio}\\
                X_k \randomsample D_k\\
                T_k \gets \mathbf{enroll}(k,X_k)\\
                res_i = \mathbf{Auth}(Y_i, T_k, k)
              } 
            \end{bbrbox}
          \end{bbrchallenger}
          \bbrchallengerqryto{top=$pk_{k}$}
          \bbrchallengerqryfrom{top=$Y_{i}$}
          \bbrchallengerqryto{top=$V_c^i$}
          \bbrchallengerqryto{top=$res_{i}$}
          % \bbrchallengerqryto{top=$m_{2}$}
        \end{bbrenv}
      \end{center}
      \caption{Impersonation Attack Game}
      \label{fig:impersonationAttackGame}
    \end{figure}


  \item[Multifactor Attack Game.] This model extends the above protocol and
    captures the client side attacks mentioned in section \ref{sec:privacyReqs}.
    \begin{description}
    \item[Setup:] The setup phase includes 2 steps:
      \begin{itemize}
      \item $\challenger$ samples $X_k \randomsample D_{k}$ from a random
        $\user_k$ ($D_k \randomsample D_{bio}$).
      \item $\challenger$ runs $\textbf{Enroll}(k, X_k)$, which returns $(sk_k, T_k)$.
      \end{itemize}
    \item[Query:] In the query phase:
      \begin{itemize}
      \item $\attacker$ is given access to the authentication oracle
        $\mathbf{Auth}(Y)$ returning the authentication result of $\user_k$ with
        a query template $Y$.
      \item $\attacker$ chooses the attack type $t \in \{I,II\}$ which specifies
        the scenario of key exposure or template exposure.

      \item $\challenger$ passes $sk_k$ if $t = I$ or $T_k$ if $t = II$ to
        $\attacker$. Note that this model reflects the 2-factors authentication
        (the secret key and the biometric template), and, thus, if $\attacker$
        requests both factors, he loses the game.
      \item $\challenger$ and $\attacker$ run $\mathbf{Auth()}$ $q$ times, For
        the $i^{th}$ run, $\attacker$ plays the client's role, choosing and
        sending $Y_i$ to $\challenger$, $\challenger$ plays the server's role,
        replying with $res_i = \mathbf{Auth}(Y_i)$.
      \end{itemize}
    \item[Guess:] $\attacker$ wins the game if it outputs $Y$ such that
      $\mathbf{Auth}(Y) = \textbf{Accepted}$.
    \end{description}
    
    Figure \ref{fig:multifactorAttackGame} show the multi-factors attack
    game. Let $W_{2}$ be the event that $\attacker$ output $Y_{q'}$ such that
    $verify(X_{k},Y_{k}) = \mathbf{Accept}$ and let $p_{2} = \prob{W_{2}} $. We
    define $\adv$'s \textbf{active multifactor advantage} with respect to the
    protocol $\pdv$ as
    \[
      \advantage{AM}{\adv,\pdv} = |p_{2} - p_{0}|
    \]
    
    \begin{figure}[!h]
      \begin{center}
        \begin{bbrenv}{multifactorSecurity}
          \begin{bbrbox}[name=Adversary, minheight=3cm]
            \pseudocode{
              \\
              type \gets \{I,II\}\\
              \text{For } i = 1, \dots, q:\\
              Y_i \gets \{0,1\}^n
            }
          \end{bbrbox}
          \bbroutput{$Y_{q}'$}
          \begin{bbrchallenger}{multifactorChallenger}
            \begin{bbrbox}[name=Challenger, minheight=2cm]
              \pseudocode{
                \\
                (\pk,\sk) \gets KeyGen\\
                D_k \randomsample D_{bio}\\
                X_k \randomsample D_k\\
                T_k \gets \mathbf{enroll}(k,X_k)\\
                res_i = \mathbf{Auth}(Y_i, T_k, k)
              } 
            \end{bbrbox}
          \end{bbrchallenger}
          \bbrchallengerqryto{top=$pk_{k}$}
          \bbrchallengerqryfrom{top=type I,bottom=or II}
          \bbrchallengerqryto{top=$sk$,bottom=or $D_{k}$}
          \bbrchallengerqryfrom{top=$Y_{i}$}
          \bbrchallengerqryto{top=$V_c^i$}
          \bbrchallengerqryto{top=$res_{i}$}
          % \bbrchallengerqryto{top=$m_{2}$}
        \end{bbrenv}
      \end{center}
      \caption{Multi-factors Attack Game}
      \label{fig:multifactorAttackGame}
    \end{figure}
    
    Similar to the previous impersonation attack game, We would want this
    advantage value not to be too large compared to the non-privacy-preserving
    biometric impersonation model's advantage, which was bounded by
    $q \times FAR$.
  \end{description}

\end{description}
\begin{definition}
  [Active Multi-factors.] A privacy-preserving biometrics authentication
  protocol $\pdv$ is c-secure against active multi-factors attack if for all
  efficient adversary $\adv$, the value $\advantage{AM}{\adv,\pdv}$ is not
  larger than $c \times FAR$ of the non-private protocol.
\end{definition}

\section{Security Proof Technique}
In the security proofs of the protocols appearing in the next chapters, we will typically
model the security games following the generic framework defined in this
chapter, with the \textbf{Enroll} and \textbf{Auth} modules replaced by concrete
lattice-based constructions (or combination of them). Each attack game is
modelled by way of a probability space, as both \textit{adversary} and
\textit{challenger} are probabilistic processes communicating with each other. The
definition of security is tied to some particular event S as seen in previous
sections (where security means that for all \textit{efficient} adversary, the
probability that event S happens is \textit{close to} some target probability,
normally \textit{negligibly} small, 1/2, or FAR in one of our contexts). In
formal definitions, there is a security parameter related to the terms
\textit{efficient} or \textit{negligible}. For example, \textit{efficient} means
time bounded by a polynomial in the security parameter, \textit{close to} means
the difference is smaller than inverse of any polynomial in the security
parameter. For simplicity, we assume that all algorithms, adversaries,
challengers, etc., take this parameter value as an implicit input.

The approach used in the security proofs is called \textit{sequence-of-games},
the process is as follows. In each proof,  a sequence of games is set up:
Game 0, Game 1, \dots, Game $n$, where Game 0 is normally the original attack
game with respect to a concrete protocol and a given adversary. Let $S_{0}$ be
the event S. For i=1,\dots,n, the construction defines an event $S_{i}$ for each
Game $i$, these events are normally related to S in a natural way. Then, the
proof shows that $\prob{S_{i}}$ is \textit{close to} $\prob{S_{i+1}}$ for all
$i=0,\dots,n-1$. Finally, if $\prob{S_{n}}$ can be shown to be \textit{close to}
the ``target probability'', provided that $n$ is a constant, we can infer that
$\prob{S}$ is negligibly close to the ``target probability'', and security is
proved. We have ensured that the changes from one game $i$ to the next game
$i+1$ are kept as small as to avoid major complications while analyzing them.

Generally, there are two types of changes in the proofs:
\begin{description}
\item[Change based on indistinguishability] A change is made such that its detection by the adversary implies a method of distinguishing two
  distributions that are statistically or computationally indistinguishable. For
  instance, if $P_{1}$ and $P_{2}$ are two indistinguishable distributions,
  to prove that $|\prob{S_{i}} - \prob{S_{i+1}}|$ is negligible, it should be shown
  that there exists an algorithm $D$ such that, when inputting an
  element drawn from $P_{1}$, outputs 1 with probability $\prob{S_{i}}$; and
  when inputting an element drawn from $P_{2}$, outputs 1 with
  probability $\prob{S_{i+1}}$. It follows that
  $|\prob{S_{i}} - \prob{S_{i+1}}|$ is negligible, provided the
  indistinguishability assumption of $P_{1}$ and $P_{2}$.
\item[Change based on failure events] This type of change is based on the fact
  that, given $A,B,F$ as events in some distribution, and supposing that
  $A \wedge \neg F \iff B \wedge \neg F$, then
  $|\prob{A} - \prob{B}| \leq \prob{F}$, to say that two games proceed
  identically unless F occurs, means that $S_{i} \wedge \neg F$ and
  $S_{i+1} \wedge \neg F$ are the same. So, in order to prove that $\prob{S_{i}}$ is
  negligibly close to $\prob{S_{i+1}}$, it is enough to prove that $\prob{F}$ is
  negligible. This can be done using the security assumption or an
  information-theoretic argument, as, for instance, that when F occurs, the adversary
  could find a collision in a cryptographic hash function.
\end{description}

\subsection{Related work}
\label{sec:proofRelatedWork}

Sequence of transitions based on indistinguishability (only) have been used
extensively in cryptography for many years. For example, in 1984,
\cite{goldreich1984construct} illustrated the ``hybrid arguments'' technique while
constructing pseudo-random functions. \cite{bellare1989new} was an early example
of a proof that is structured as a sequence of games including transitions based
on both failure events and indistinguishability. The first formal approach to
sequences of games was initiated by Kilian and Rogaway's paper
\cite{kilian1996protect}. The authors subsequently applied the technique in
numerous papers, detailed introduction to the methodology and references of usage
can be found in \cite{bellare2004game}. In Bellare and Rogaway's approach, games
are treated as syntactic objects subject to formal manipulation, while
\cite{shoup2004sequences} views games as probability spaces with random variables
defined over them. This proof style is also illustrated nicely by some public
key cryptography examples in an introductory manuscript
\cite{pointcheval2005provable}. The technique has been used widely
(\cite{abdalla2005password}, \cite{boneh2005improved}, \cite{bresson2002group},
etc. ). While some of the proofs can be structured differently,
sequence-of-games is a technique able of accomplishing the task in a clear and
convincing way.

\section{Conclusion}
This chapter lays out the framework to be used as the security models and hints at the way
security proofs will be organized. The technique (sequence-of-games) will
be used subsequently in the next chapters within each of the protocol variants to
illustrate to illustrate correspondingly security properties. 
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: